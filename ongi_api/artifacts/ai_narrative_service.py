"""
AI ì„œìˆ í˜• ì„¤ëª… ìë™ ìƒì„± ì„œë¹„ìŠ¤
ìœ ë¬¼ ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ì†Œì„¤ì²˜ëŸ¼ ì„œìˆ ëœ ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤.
Ollama llama3.1:8b ëª¨ë¸ ì‚¬ìš©
"""
import logging
from typing import Optional

logger = logging.getLogger(__name__)


class AiNarrativeService:
    """AI ì„œìˆ í˜• ì„¤ëª… ìƒì„± ì„œë¹„ìŠ¤ (Ollama ê¸°ë°˜)"""

    @staticmethod
    def _create_narrative_prompt(artifact_name: str) -> str:
        """
        ì„œìˆ í˜• ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            artifact_name: ìœ ë¬¼ ì´ë¦„

        Returns:
            í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        return f"""ë‹¹ì‹ ì€ í•œêµ­ ë¬¸í™”ìœ ì‚° ì „ë¬¸ í•´ì„¤ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ìœ ë¬¼ì— ëŒ€í•´ ì†Œì„¤ì²˜ëŸ¼ ì•„ë¦„ë‹µê³  ì„œìˆ ì ì¸ ì„¤ëª…ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ğŸ“Œ ìœ ë¬¼ ì´ë¦„: {artifact_name}

ğŸ“ ì‘ì„± ê·œì¹™:
1. 3ê°œì˜ ë‹¨ë½ìœ¼ë¡œ êµ¬ì„± (ê° ë‹¨ë½ì€ 2-3ë¬¸ì¥)
2. ì²« ë‹¨ë½: ìœ ë¬¼ì˜ ì—­ì‚¬ì  ë°°ê²½ê³¼ ì‹œëŒ€ì  ì˜ë¯¸
3. ë‘˜ì§¸ ë‹¨ë½: ìœ ë¬¼ì˜ ê±´ì¶•/ì œì‘ íŠ¹ì§•ê³¼ ê³¼í•™ì /ì˜ˆìˆ ì  ê°€ì¹˜
4. ì…‹ì§¸ ë‹¨ë½: í˜„ì¬ê¹Œì§€ ì´ì–´ì§„ ë¬¸í™”ì  ì˜ë¯¸ì™€ ê°ë™
5. ë¬¸ì²´: ì„œì •ì ì´ê³  í’ˆê²©ìˆëŠ” ë¬¸ì–´ì²´ ì‚¬ìš©
6. ì‚¬ì‹¤ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë˜, ê°ì„±ì ìœ¼ë¡œ ì„œìˆ 
7. ì´ 200-300ì ì •ë„ì˜ ë¶„ëŸ‰
8. ì¡´ëŒ“ë§ ì‚¬ìš©í•˜ì§€ ì•Šê³  í‰ì„œë¬¸ìœ¼ë¡œ ì‘ì„±

ìœ„ ìœ ë¬¼ì— ëŒ€í•œ AI í•´ì„¤:"""

    @staticmethod
    def generate_narrative_with_ollama(artifact_name: str) -> Optional[str]:
        """
        Ollamaë¥¼ ì‚¬ìš©í•˜ì—¬ AI ì„œìˆ í˜• ì„¤ëª… ìƒì„±

        Args:
            artifact_name: ìœ ë¬¼ ì´ë¦„

        Returns:
            ìƒì„±ëœ ì„œìˆ í˜• ì„¤ëª… ë˜ëŠ” None
        """
        try:
            # OllamaService import (ìˆœí™˜ ì°¸ì¡° ë°©ì§€ë¥¼ ìœ„í•´ í•¨ìˆ˜ ë‚´ì—ì„œ import)
            from .services import OllamaService
            import httpx
            import json

            # ì„œìˆ í˜• í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = AiNarrativeService._create_narrative_prompt(artifact_name)

            # Ollama API í˜¸ì¶œ
            full_text = ""

            with httpx.stream(
                'POST',
                f'{OllamaService.OLLAMA_BASE_URL}/api/generate',
                json={
                    'model': OllamaService.DEFAULT_MODEL,
                    'prompt': prompt,
                    'stream': True,
                    'options': {
                        'temperature': 0.7,
                        'top_p': 0.9,
                        'num_predict': 500,
                    }
                },
                timeout=60.0
            ) as response:

                if response.status_code != 200:
                    logger.error(f'Ollama API error: {response.status_code}')
                    return None

                for line in response.iter_lines():
                    if line.strip():
                        try:
                            data = json.loads(line)

                            if 'response' in data:
                                full_text += data['response']

                            if data.get('done', False):
                                break

                        except json.JSONDecodeError as e:
                            logger.error(f'JSON decode error: {str(e)}')
                            continue

            narrative = full_text.strip()
            logger.info(f"Generated narrative for '{artifact_name}': {len(narrative)} characters")

            return narrative if narrative else None

        except Exception as e:
            logger.error(f"Error generating narrative with Ollama: {e}")
            return None

    @staticmethod
    def generate_narrative_template(artifact_name: str) -> str:
        """
        í…œí”Œë¦¿ ê¸°ë°˜ ì„œìˆ í˜• ì„¤ëª… ìƒì„± (Fallback)

        Args:
            artifact_name: ìœ ë¬¼ ì´ë¦„

        Returns:
            í…œí”Œë¦¿ ê¸°ë°˜ ì„œìˆ í˜• ì„¤ëª…
        """
        # ìœ ë¬¼ë³„ í…œí”Œë¦¿ (í•˜ë“œì½”ë”©)
        templates = {
            "ì²¨ì„±ëŒ€": """ì‹ ë¼ì˜ ë°¤í•˜ëŠ˜ì„ í–¥í•´ ì²œ ë…„ì˜ ì‹œê°„ì„ ê²¬ëŒì˜¨ ì²¨ì„±ëŒ€. ì„ ë•ì—¬ì™• ì‹œëŒ€ì¸ 632ë…„ë¶€í„° 647ë…„ ì‚¬ì´ì— ì„¸ì›Œì§„ ì´ ì²œë¬¸ ê´€ì¸¡ëŒ€ëŠ” ë™ì–‘ì—ì„œ ê°€ì¥ ì˜¤ë˜ëœ í˜„ì¡´í•˜ëŠ” ì²œë¬¸ëŒ€ì…ë‹ˆë‹¤.

362ê°œì˜ í™”ê°•ì•”ì„ ì •êµí•˜ê²Œ ìŒ“ì•„ ì˜¬ë¦° ìš°ì•„í•œ ê³¡ì„ ì€ ë‹¨ìˆœí•œ ê±´ì¶•ë¯¸ë¥¼ ë„˜ì–´, ë‹¹ì‹œ ì‹ ë¼ì¸ë“¤ì˜ ë†€ë¼ìš´ ê³¼í•™ì  ì§€í˜œë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ë†’ì´ 9.17ë¯¸í„°ì˜ ì´ íƒ‘ì€ ì¼ë…„ì˜ ë‚ ìˆ˜ì™€ 24ì ˆê¸°ë¥¼ ìƒì§•í•˜ë©°, í•˜ëŠ˜ê³¼ ë•…ì„ ì‡ëŠ” ìš°ì£¼ë¡ ì  ì˜ë¯¸ë¥¼ ê°„ì§í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ì²œë…„ì´ ì§€ë‚œ ì§€ê¸ˆë„ ê²½ì£¼ ë“¤íŒì— ìš°ëš ì„œì„œ, ë³„ì„ ê´€ì¸¡í•˜ë˜ ì‹ ë¼ ì²œë¬¸í•™ìë“¤ì˜ ì—´ì •ê³¼ ì§€í˜œë¥¼ ìš°ë¦¬ì—ê²Œ ì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.""",
        }

        # ìœ ë¬¼ ì´ë¦„ ì •ê·œí™”
        normalized_name = artifact_name.strip().lower()

        # í…œí”Œë¦¿ì—ì„œ ì°¾ê¸°
        for key, template in templates.items():
            if key.lower() in normalized_name or normalized_name in key.lower():
                return template

        # í…œí”Œë¦¿ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ë©”ì‹œì§€
        return f"""{artifact_name}ì€(ëŠ”) ìš°ë¦¬ì˜ ì†Œì¤‘í•œ ë¬¸í™”ìœ ì‚°ì…ë‹ˆë‹¤.

ì„ ì¡°ë“¤ì˜ ì§€í˜œì™€ ê¸°ìˆ ì´ ë‹´ê¸´ ì´ ìœ ë¬¼ì€ ì‹œê°„ì„ ë„˜ì–´ ì˜¤ëŠ˜ë‚ ê¹Œì§€ ê·¸ ê°€ì¹˜ë¥¼ ì¸ì •ë°›ê³  ìˆìŠµë‹ˆë‹¤.

ì•ìœ¼ë¡œë„ ì´ ë¬¸í™”ìœ ì‚°ì´ í›„ëŒ€ì— ì˜ ì „ìŠ¹ë˜ì–´, ìš°ë¦¬ì˜ ì—­ì‚¬ì™€ ì •ì²´ì„±ì„ ì´ì–´ê°€ëŠ” ì†Œì¤‘í•œ ë§¤ê°œì²´ê°€ ë˜ê¸°ë¥¼ ë°”ëë‹ˆë‹¤."""

    @staticmethod
    def generate_narrative(artifact_name: str, use_ai: bool = True) -> str:
        """
        AI ì„œìˆ í˜• ì„¤ëª… ìƒì„±

        Args:
            artifact_name: ìœ ë¬¼ ì´ë¦„
            use_ai: Ollama AI ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)

        Returns:
            ìƒì„±ëœ ì„œìˆ í˜• ì„¤ëª…
        """
        if not artifact_name:
            return ""

        # Ollama ì‚¬ìš© ì‹œë„
        if use_ai:
            narrative = AiNarrativeService.generate_narrative_with_ollama(artifact_name)
            if narrative:
                return narrative
            logger.info(f"Falling back to template for '{artifact_name}'")

        # Fallback: í…œí”Œë¦¿ ì‚¬ìš©
        return AiNarrativeService.generate_narrative_template(artifact_name)
